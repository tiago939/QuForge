{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7a98ed-2567-4ca1-83bf-aa96cff89e81",
   "metadata": {},
   "source": [
    "# Iris CLASSIFIER\n",
    "### Let's build a quantum variational algorithm to classify the Iris flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30114de4-89ba-4218-83fe-2fdf5ba7ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import the libaries\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.append('../')\n",
    "import quforge.quforge as qf\n",
    "from quforge.quforge import State as State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3508ded9-c1e0-4b72-a749-16d036de4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = iris['data']\n",
    "labels = iris['target']\n",
    "\n",
    "ids = random.sample(range(len(data)), len(data))\n",
    "ids_train = ids[0:int(0.8*len(data))]\n",
    "ids_test = ids[int(0.8*len(data)):len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3dc8434-1041-427d-990b-f87eae31e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "\n",
    "class Circuit(qf.Module):\n",
    "    def __init__(self, dim, wires):\n",
    "        super(Circuit, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.init = qf.H(dim=dim, index=range(wires))\n",
    "        self.encoder = qf.RZ(dim=dim, index=range(wires))\n",
    "\n",
    "        self.layers = qf.Sequential(\n",
    "            qf.RX(dim=dim, j=0, k=1, index=range(wires)),\n",
    "            qf.RX(dim=dim, j=1, k=2, index=range(wires)),\n",
    "            qf.RX(dim=dim, j=0, k=2, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=0, k=1, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=1, k=2, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=0, k=2, index=range(wires)),\n",
    "            qf.RZ(dim=dim, j=1, index=range(wires)),\n",
    "            qf.RZ(dim=dim, j=2, index=range(wires)),\n",
    "            qf.CNOT(dim=dim, wires=wires, index=[0,1]),\n",
    "            qf.CNOT(dim=dim, wires=wires, index=[0,2]),\n",
    "            qf.CNOT(dim=dim, wires=wires, index=[0,3]),\n",
    "            qf.RX(dim=dim, j=0, k=1, index=range(wires)),\n",
    "            qf.RX(dim=dim, j=1, k=2, index=range(wires)),\n",
    "            qf.RX(dim=dim, j=0, k=2, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=0, k=1, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=1, k=2, index=range(wires)),\n",
    "            qf.RY(dim=dim, j=0, k=2, index=range(wires)),\n",
    "            qf.RZ(dim=dim, j=1, index=range(wires)),\n",
    "            qf.RZ(dim=dim, j=2, index=range(wires)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = State('0-0-0-0', dim=self.dim, device=device)\n",
    "        y = self.init(y)\n",
    "        y = self.encoder(y, param=x)\n",
    "        y = self.layers(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e4c8e8-17c4-4719-b1a0-fc64198197e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate model and optimizer\n",
    "dim = 3 #dimension of the qudit\n",
    "device = 'cuda'\n",
    "\n",
    "model = Circuit(dim=dim, wires=4).to(device)\n",
    "optimizer = qf.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7e6aa5-f25d-431d-8602-ac426043fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the target states\n",
    "targets = [State('1-0-0', dim=dim, device=device).flatten(), State('0-1-0', dim=dim, device=device).flatten(), State('0-0-1', dim=dim, device=device).flatten()]\n",
    "targets_arg = [qf.argmax(abs(targets[0])), qf.argmax(abs(targets[1])), qf.argmax(abs(targets[2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ecef5f-8462-4367-9a2d-9dc0173bfca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6916666666666667 0.5\n",
      "1 0.6916666666666667 0.5333333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m data[k]\n\u001b[1;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m labels[k]\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m _, m \u001b[38;5;241m=\u001b[39m qf\u001b[38;5;241m.\u001b[39mmeasure(output, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m qf\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mabs\u001b[39m(targets[label] \u001b[38;5;241m-\u001b[39m m))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mCircuit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit(y)\n\u001b[1;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(y, param\u001b[38;5;241m=\u001b[39mx)\n\u001b[0;32m---> 37\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/qudit machine learning/QuForge/examples/../quforge/quforge.py:525\u001b[0m, in \u001b[0;36mRZ.forward\u001b[0;34m(self, x, param)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((values, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdevice)))\n\u001b[1;32m    523\u001b[0m         M \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(indices, values, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 525\u001b[0m     U \u001b[38;5;241m=\u001b[39m \u001b[43mkron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     U \u001b[38;5;241m=\u001b[39m kron(U, eye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse))\n",
      "File \u001b[0;32m~/research/qudit machine learning/QuForge/examples/../quforge/quforge.py:204\u001b[0m, in \u001b[0;36mkron\u001b[0;34m(matrix1, matrix2, sparse)\u001b[0m\n\u001b[1;32m    201\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(pos, val, size\u001b[38;5;241m=\u001b[39m(D1 \u001b[38;5;241m*\u001b[39m D2, D1 \u001b[38;5;241m*\u001b[39m D2))\u001b[38;5;241m.\u001b[39mto(matrix1\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Optimize the model\n",
    "for epoch in range(8):\n",
    "    acc_train = 0.0\n",
    "    acc_test = 0.0\n",
    "    \n",
    "    for k in ids_train:\n",
    "        x = data[k]\n",
    "        label = labels[k]\n",
    "        output = model(x)\n",
    "        \n",
    "        _, m = qf.measure(output, index=[0, 1, 2], dim=dim)\n",
    "        \n",
    "        loss = qf.mean(abs(targets[label] - m))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predict = qf.argmax(m)\n",
    "        if predict == targets_arg[label]:\n",
    "            acc_train += 1\n",
    "\n",
    "    for k in ids_test:\n",
    "        x = data[k]\n",
    "        label = labels[k]\n",
    "        output = model(x)\n",
    "        \n",
    "        _, m = qf.measure(output, index=[0, 1, 2], dim=dim)\n",
    "\n",
    "        predict = qf.argmax(m)\n",
    "        if predict == targets_arg[label]:\n",
    "            acc_test += 1\n",
    "    \n",
    "    acc_train = acc_train/len(ids_train)\n",
    "    acc_test = acc_test/len(ids_test)\n",
    "\n",
    "    print(epoch, acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7ee45-f2a8-4566-95d3-9eaa7759407c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f11268-4842-459f-8bef-e56ebfb65955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
